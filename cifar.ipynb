{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>CIFAR-10 Keras implementation</b>\n",
    "<br>\n",
    "This is my implementation for the CIFAR-10 contest conducted by kaggle\n",
    "The training data is inside the folder './train/train/'\n",
    "while testing data is inside './test/'\n",
    "\n",
    "This implementation achieved an accuracy of 82%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "from os import path\n",
    "np.random.seed(2)\n",
    "from os import listdir\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import cv2\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input, Activation, add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import RMSprop, SGD, Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau,ModelCheckpoint\n",
    "sns.set(style='white', context='notebook', palette='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read training labels\n",
    "label = pd.read_csv(\"./train/trainLabels.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the unique label names\n",
    "a = np.unique(label['label'])\n",
    "a.sort\n",
    "# convert label names to numericals\n",
    "Y_train = label['label'].apply(a.tolist().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9    5000\n",
       "8    5000\n",
       "7    5000\n",
       "6    5000\n",
       "5    5000\n",
       "4    5000\n",
       "3    5000\n",
       "2    5000\n",
       "1    5000\n",
       "0    5000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa0b5ed5e90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check frequency of occurence of each label\n",
    "g = sns.countplot(Y_train)\n",
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "Y_train = to_categorical(Y_train, num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to read images and convert to numpy array. \n",
    "def read_all_images(DIR = './',batch_size=0,st=0):\n",
    "    l = listdir(DIR)\n",
    "    l = [s.replace('.png', '') for s in l]\n",
    "    l = map(int,l)\n",
    "    l.sort()\n",
    "    if batch_size == 0:\n",
    "        batch_size = len(l)\n",
    "    \n",
    "    ims = np.zeros((batch_size,32,32,3),dtype=np.uint8)\n",
    "    print \"Starting from {}\".format(st)\n",
    "    for i in range(batch_size):\n",
    "        img = cv2.imread(DIR+str(l[i+st]) + '.png')\n",
    "        img.reshape(32,32,3)\n",
    "        ims[i,:,:,:] = img\n",
    "    return ims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the numpy array for training\n",
    "if path.isfile('./train.npy'):\n",
    "    X_train = np.load('./train.npy')\n",
    "else:\n",
    "    X_train = read_all_images('./train/train/')\n",
    "    np.save('./train.npy',X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data set\n",
    "X_train = X_train / 255.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "# check = X_train[9]\n",
    "# cv2.imshow('img',check)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Y_train[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the random seed\n",
    "random_seed = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the train and the validation set for the fitting 20% val\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.2, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sanity check\n",
    "# check = X_train[10]\n",
    "# cv2.imshow('img',check)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y_train[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data augmentation to prevent overfitting \n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.2, # Randomly zoom image \n",
    "        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keras functional API preload is used to continue training when interrupted\n",
    "def my_model(preload = None):\n",
    "    \n",
    "    inputs = Input(shape=(32,32,3))\n",
    "    \n",
    "    conv1 = Conv2D(32,(3,3),padding='same')(inputs)\n",
    "    conv1 = BatchNormalization(axis=-1)(conv1)\n",
    "    conv1 = Activation('relu')(conv1)\n",
    "    \n",
    "    conv1 = Conv2D(32,(3,3),padding='same')(conv1)\n",
    "    conv1 = BatchNormalization(axis=-1)(conv1)\n",
    "    conv1 = Activation('relu')(conv1)\n",
    "    \n",
    "    pool1 = MaxPool2D((2,2),padding='same')(conv1)\n",
    "    pool1 = Dropout(0.2)(pool1)\n",
    "    \n",
    "    conv2 = Conv2D(64,(3,3),padding='same')(pool1)\n",
    "    conv2 = BatchNormalization(axis=-1)(conv2)\n",
    "    conv2 = Activation('relu')(conv2)\n",
    "    \n",
    "    conv2 = Conv2D(64,(3,3),padding='same')(conv2)\n",
    "    conv2 = BatchNormalization(axis=-1)(conv2)\n",
    "    conv2 = Activation('relu')(conv2)\n",
    "    \n",
    "    pool2 = MaxPool2D((2,2),padding='same')(conv2)\n",
    "    pool2 = Dropout(0.2)(pool2)\n",
    "\n",
    "    flat = Flatten()(pool2)\n",
    "    \n",
    "    dense = Dense(256,activation = 'relu')(flat)\n",
    "    dense = Dropout(0.2)(dense)\n",
    "\n",
    "    dense = Dense(128,activation = 'relu')(dense)\n",
    "    dense = Dropout(0.2)(dense)\n",
    "    \n",
    "    out = Dense(10,activation='softmax')(dense)\n",
    "    \n",
    "    model = Model(inputs,out)\n",
    "    \n",
    "    if preload:\n",
    "        model.load_weights(preload)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "optimizer = Adam(lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# callback to save weights with least validation loss\n",
    "bestval = ModelCheckpoint('bestval.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create and compile model\n",
    "model = my_model('bestval.h5')\n",
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define epochs and batch_size\n",
    "epochs = 50 \n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set a learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
    "                              epochs = epochs, validation_data = (X_val,Y_val),\n",
    "                              verbose = 1, steps_per_epoch=X_train.shape[0] // batch_size\n",
    "                              , callbacks=[learning_rate_reduction,bestval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the loss and accuracy curves for training and validation \n",
    "fig, ax = plt.subplots(2,1)\n",
    "ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "ax[1].plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\n",
    "legend = ax[1].legend(loc='best', shadow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load model with best weights\n",
    "model.load_weights('bestval.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at confusion matrix \n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Predict the values from the validation dataset\n",
    "Y_pred = model.predict(X_val)\n",
    "# Convert predictions classes to one hot vectors \n",
    "Y_pred_classes = np.argmax(Y_pred,axis = 1) \n",
    "# Convert validation observations to one hot vectors\n",
    "Y_true = np.argmax(Y_val,axis = 1) \n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes = range(10)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some error results \n",
    "\n",
    "# Errors are difference between predicted labels and true labels\n",
    "errors = (Y_pred_classes - Y_true != 0)\n",
    "\n",
    "Y_pred_classes_errors = Y_pred_classes[errors]\n",
    "Y_pred_errors = Y_pred[errors]\n",
    "Y_true_errors = Y_true[errors]\n",
    "X_val_errors = X_val[errors]\n",
    "\n",
    "def display_errors(errors_index,img_errors,pred_errors, obs_errors):\n",
    "    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n",
    "    n = 0\n",
    "    nrows = 2\n",
    "    ncols = 3\n",
    "    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n",
    "    for row in range(nrows):\n",
    "        for col in range(ncols):\n",
    "            error = errors_index[n]\n",
    "            ax[row,col].imshow((img_errors[error]).reshape((32,32,3)))\n",
    "            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n",
    "            n += 1\n",
    "\n",
    "# Probabilities of the wrong predicted numbers\n",
    "Y_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n",
    "\n",
    "# Predicted probabilities of the true values in the error set\n",
    "true_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n",
    "\n",
    "# Difference between the probability of the predicted label and the true label\n",
    "delta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n",
    "\n",
    "# Sorted list of the delta prob errors\n",
    "sorted_dela_errors = np.argsort(delta_pred_true_errors)\n",
    "\n",
    "# Top 6 errors \n",
    "most_important_errors = sorted_dela_errors[-6:]\n",
    "\n",
    "# Show the top 6 errors\n",
    "display_errors(most_important_errors, X_val_errors, Y_pred_classes_errors, Y_true_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For prediction read a batch of 1000 images and append results\n",
    "results = np.zeros((1))\n",
    "for i in range(300):\n",
    "    print \"Predicting batch {} of {} \".format(i+1,300)\n",
    "    test = read_all_images('./train/test/',1000,i*1000)\n",
    "    test = test / 255.\n",
    "    prediction = model.predict(test)\n",
    "    prediction = np.argmax(prediction,axis=1)\n",
    "    results = np.append(results,prediction)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Remove extra element and convert to int\n",
    "results = results[1:]\n",
    "results = map(int,results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert label numbers to names\n",
    "results = a[results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a table\n",
    "results = pd.Series(results,name=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.concat([pd.Series(range(1,300001),name = \"id\"),results],axis = 1)\n",
    "\n",
    "submission.to_csv(\"submit.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
